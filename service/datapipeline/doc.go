// Code generated by private/model/cli/gen-api/main.go. DO NOT EDIT.

// Package datapipeline provides the client and types for making API
// requests to AWS Data Pipeline.
//
// AWS Data Pipeline configures and manages a data-driven workflow called a
// pipeline. AWS Data Pipeline handles the details of scheduling and ensuring
// that data dependencies are met so that your application can focus on processing
// the data.
//
// AWS Data Pipeline provides a JAR implementation of a task runner called AWS
// Data Pipeline Task Runner. AWS Data Pipeline Task Runner provides logic for
// common data management scenarios, such as performing database queries and
// running data analysis using Amazon Elastic MapReduce (Amazon EMR). You can
// use AWS Data Pipeline Task Runner as your task runner, or you can write your
// own task runner to provide custom data management.
//
// AWS Data Pipeline implements two main sets of functionality. Use the first
// set to create a pipeline and define data sources, schedules, dependencies,
// and the transforms to be performed on the data. Use the second set in your
// task runner application to receive the next task ready for processing. The
// logic for performing the task, such as querying the data, running data analysis,
// or converting the data from one format to another, is contained within the
// task runner. The task runner performs the task assigned to it by the web
// service, reporting progress to the web service as it does so. When the task
// is done, the task runner reports the final success or failure of the task
// to the web service.
//
// See https://docs.aws.amazon.com/goto/WebAPI/datapipeline-2012-10-29 for more information on this service.
//
// See https://docs.aws.amazon.com/sdk-for-go/api/service/datapipeline/
// for information on using this package.
//
// Using the Client
//
// To use the DataPipeline client for AWS Data Pipeline you will
// first need to create a new instance of it. Once the service's client is created
// you can begin to make API requests to the service using it. The client is safe
// to use across multiple goroutines concurrently.
//
// All clients require a Session. The Session provides the client with shared
// configuration such as region, endpoint, and credentials. A Session should be
// shared where possible to take advantage of configuration and credential caching.
// See the github.com/aws/aws-sdk-go/aws/session package for more information.
//
//   sess := session.Must(session.NewSession())
//
// Create a new instance of the service's client with a Session. Optional
// aws.Config values can also be provided as variadic arguments to the
// New function. This option allows you to provide service specific configuration.
//
//   svc := datapipeline.New(sess)
//
// Once the client is created you can make an API request to the service.
// Each API method takes a input parameter, and returns the service response
// and an error.
//
// The API method will document which error codes the service can be returned
// by the operation if the service models the API operation's errors. These errors
// will also be available as const strings prefixed with "ErrCode".
//
//   result, err := svc.ActivatePipeline(params)
//   if err != nil {
//       // Cast err to awserr.Error to handle specific error codes.
//       aerr, ok := err.(awserr.Error)
//       if ok && aerr.Code() == <error code to check for> {
//           // Specific error code handling
//       }
//       return err
//   }
//
//   fmt.Println("ActivatePipeline result:")
//   fmt.Println(result)
//
// Using the Client with Context
//
// The service's client also provides methods to make API requests with a Context
// value. This allows you to control the timeout, and cancellation of pending
// requests. These methods also take request Option as variadic parameter to apply
// additional configuration to the API request. See the github.com/aws/aws-sdk-go/aws/request
// package for more information.
//
//   ctx := context.Background()
//
//   result, err := svc.ActivatePipelineWithContext(ctx, params)
package datapipeline
