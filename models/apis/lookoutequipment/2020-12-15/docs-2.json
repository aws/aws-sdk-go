{
  "version": "2.0",
  "service": "<p>Amazon Lookout for Equipment is a machine learning service that uses advanced analytics to identify anomalies in machines from sensor data for use in predictive maintenance. </p>",
  "operations": {
    "CreateDataset": "<p>Creates a container for a collection of data being ingested for analysis. The dataset contains the metadata describing where the data is and what the data actually looks like. In other words, it contains the location of the data source, the data schema, and other information. A dataset also contains any tags associated with the ingested data. </p>",
    "CreateInferenceScheduler": "<p> Creates a scheduled inference. Scheduling an inference is setting up a continuous real-time inference plan to analyze new measurement data. When setting up the schedule, you provide an S3 bucket location for the input data, assign it a delimiter between separate entries in the data, set an offset delay if desired, and set the frequency of inferencing. You must also provide an S3 bucket location for the output data. </p>",
    "CreateLabel": "<p> Creates a label for an event. </p>",
    "CreateLabelGroup": "<p> Creates a group of labels. </p>",
    "CreateModel": "<p>Creates an ML model for data inference. </p> <p>A machine-learning (ML) model is a mathematical model that finds patterns in your data. In Amazon Lookout for Equipment, the model learns the patterns of normal behavior and detects abnormal behavior that could be potential equipment failure (or maintenance events). The models are made by analyzing normal data and abnormalities in machine behavior that have already occurred.</p> <p>Your model is trained using a portion of the data from your dataset and uses that data to learn patterns of normal behavior and abnormal patterns that lead to equipment failure. Another portion of the data is used to evaluate the model's accuracy. </p>",
    "DeleteDataset": "<p> Deletes a dataset and associated artifacts. The operation will check to see if any inference scheduler or data ingestion job is currently using the dataset, and if there isn't, the dataset, its metadata, and any associated data stored in S3 will be deleted. This does not affect any models that used this dataset for training and evaluation, but does prevent it from being used in the future. </p>",
    "DeleteInferenceScheduler": "<p>Deletes an inference scheduler that has been set up. Already processed output results are not affected. </p>",
    "DeleteLabel": "<p> Deletes a label. </p>",
    "DeleteLabelGroup": "<p> Deletes a group of labels. </p>",
    "DeleteModel": "<p>Deletes an ML model currently available for Amazon Lookout for Equipment. This will prevent it from being used with an inference scheduler, even one that is already set up. </p>",
    "DescribeDataIngestionJob": "<p>Provides information on a specific data ingestion job such as creation time, dataset ARN, and status.</p>",
    "DescribeDataset": "<p>Provides a JSON description of the data in each time series dataset, including names, column names, and data types.</p>",
    "DescribeInferenceScheduler": "<p> Specifies information about the inference scheduler being used, including name, model, status, and associated metadata </p>",
    "DescribeLabel": "<p> Returns the name of the label. </p>",
    "DescribeLabelGroup": "<p> Returns information about the label group. </p>",
    "DescribeModel": "<p>Provides a JSON containing the overall information about a specific ML model, including model name and ARN, dataset, training and evaluation information, status, and so on. </p>",
    "ListDataIngestionJobs": "<p>Provides a list of all data ingestion jobs, including dataset name and ARN, S3 location of the input data, status, and so on. </p>",
    "ListDatasets": "<p>Lists all datasets currently available in your account, filtering on the dataset name. </p>",
    "ListInferenceEvents": "<p> Lists all inference events that have been found for the specified inference scheduler. </p>",
    "ListInferenceExecutions": "<p> Lists all inference executions that have been performed by the specified inference scheduler. </p>",
    "ListInferenceSchedulers": "<p>Retrieves a list of all inference schedulers currently available for your account. </p>",
    "ListLabelGroups": "<p> Returns a list of the label groups. </p>",
    "ListLabels": "<p> Provides a list of labels. </p>",
    "ListModels": "<p>Generates a list of all models in the account, including model name and ARN, dataset, and status. </p>",
    "ListSensorStatistics": "<p> Lists statistics about the data collected for each of the sensors that have been successfully ingested in the particular dataset. Can also be used to retreive Sensor Statistics for a previous ingestion job. </p>",
    "ListTagsForResource": "<p>Lists all the tags for a specified resource, including key and value. </p>",
    "StartDataIngestionJob": "<p>Starts a data ingestion job. Amazon Lookout for Equipment returns the job status. </p>",
    "StartInferenceScheduler": "<p>Starts an inference scheduler. </p>",
    "StopInferenceScheduler": "<p>Stops an inference scheduler. </p>",
    "TagResource": "<p>Associates a given tag to a resource in your account. A tag is a key-value pair which can be added to an Amazon Lookout for Equipment resource as metadata. Tags can be used for organizing your resources as well as helping you to search and filter by tag. Multiple tags can be added to a resource, either when you create it, or later. Up to 50 tags can be associated with each resource. </p>",
    "UntagResource": "<p>Removes a specific tag from a given resource. The tag is specified by its key. </p>",
    "UpdateInferenceScheduler": "<p>Updates an inference scheduler. </p>",
    "UpdateLabelGroup": "<p> Updates the label group. </p>"
  },
  "shapes": {
    "AccessDeniedException": {
      "base": "<p>The request could not be completed because you do not have access to the resource. </p>",
      "refs": {
      }
    },
    "AmazonResourceArn": {
      "base": null,
      "refs": {
        "ListTagsForResourceRequest$ResourceArn": "<p>The Amazon Resource Name (ARN) of the resource (such as the dataset or model) that is the focus of the <code>ListTagsForResource</code> operation. </p>",
        "TagResourceRequest$ResourceArn": "<p>The Amazon Resource Name (ARN) of the specific resource to which the tag should be associated. </p>",
        "UntagResourceRequest$ResourceArn": "<p>The Amazon Resource Name (ARN) of the resource to which the tag is currently associated. </p>"
      }
    },
    "Boolean": {
      "base": null,
      "refs": {
        "SensorStatisticsSummary$DataExists": "<p> Parameter that indicates whether data exists for the sensor that the statistics belong to. </p>"
      }
    },
    "BoundedLengthString": {
      "base": null,
      "refs": {
        "AccessDeniedException$Message": null,
        "ConflictException$Message": null,
        "DescribeDataIngestionJobResponse$FailedReason": "<p>Specifies the reason for failure when a data ingestion job has failed. </p>",
        "DescribeDataIngestionJobResponse$StatusDetail": "<p> Provides details about status of the ingestion job that is currently in progress. </p>",
        "DescribeModelResponse$FailedReason": "<p>If the training of the ML model failed, this indicates the reason for that failure. </p>",
        "InferenceExecutionSummary$FailedReason": "<p> Specifies the reason for failure when an inference execution has failed. </p>",
        "InternalServerException$Message": null,
        "ResourceNotFoundException$Message": null,
        "ServiceQuotaExceededException$Message": null,
        "ThrottlingException$Message": null,
        "ValidationException$Message": null
      }
    },
    "CategoricalValues": {
      "base": "<p> Entity that comprises information on categorical values in data. </p>",
      "refs": {
        "SensorStatisticsSummary$CategoricalValues": "<p> Parameter that describes potential risk about whether data associated with the sensor is categorical. </p>"
      }
    },
    "Comments": {
      "base": null,
      "refs": {
        "CreateLabelRequest$Notes": "<p> Metadata providing additional information about the label. </p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>",
        "DescribeLabelResponse$Notes": "<p>Metadata providing additional information about the label.</p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>"
      }
    },
    "ComponentName": {
      "base": null,
      "refs": {
        "SensorStatisticsSummary$ComponentName": "<p> Name of the component to which the particular sensor belongs for which the statistics belong to. </p>"
      }
    },
    "ComponentTimestampDelimiter": {
      "base": null,
      "refs": {
        "InferenceInputNameConfiguration$ComponentTimestampDelimiter": "<p>Indicates the delimiter character used between items in the data. </p>"
      }
    },
    "ConflictException": {
      "base": "<p> The request could not be completed due to a conflict with the current state of the target resource. </p>",
      "refs": {
      }
    },
    "CountPercent": {
      "base": "<p> Entity that comprises information of count and percentage. </p>",
      "refs": {
        "SensorStatisticsSummary$MissingValues": "<p> Parameter that describes the total number of, and percentage of, values that are missing for the sensor that the statistics belong to. </p>",
        "SensorStatisticsSummary$InvalidValues": "<p> Parameter that describes the total number of, and percentage of, values that are invalid for the sensor that the statistics belong to. </p>",
        "SensorStatisticsSummary$InvalidDateEntries": "<p> Parameter that describes the total number of invalid date entries associated with the sensor that the statistics belong to. </p>",
        "SensorStatisticsSummary$DuplicateTimestamps": "<p> Parameter that describes the total number of duplicate timestamp records associated with the sensor that the statistics belong to. </p>"
      }
    },
    "CreateDatasetRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateDatasetResponse": {
      "base": null,
      "refs": {
      }
    },
    "CreateInferenceSchedulerRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateInferenceSchedulerResponse": {
      "base": null,
      "refs": {
      }
    },
    "CreateLabelGroupRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateLabelGroupResponse": {
      "base": null,
      "refs": {
      }
    },
    "CreateLabelRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateLabelResponse": {
      "base": null,
      "refs": {
      }
    },
    "CreateModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "CreateModelResponse": {
      "base": null,
      "refs": {
      }
    },
    "DataDelayOffsetInMinutes": {
      "base": null,
      "refs": {
        "CreateInferenceSchedulerRequest$DataDelayOffsetInMinutes": "<p>The interval (in minutes) of planned delay at the start of each inference segment. For example, if inference is set to run every ten minutes, the delay is set to five minutes and the time is 09:08. The inference scheduler will wake up at the configured interval (which, without a delay configured, would be 09:10) plus the additional five minute delay time (so 09:15) to check your Amazon S3 bucket. The delay provides a buffer for you to upload data at the same frequency, so that you don't have to stop and restart the scheduler when uploading new data.</p> <p>For more information, see <a href=\"https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/understanding-inference-process.html\">Understanding the inference process</a>.</p>",
        "DescribeInferenceSchedulerResponse$DataDelayOffsetInMinutes": "<p> A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if you select an offset delay time of five minutes, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>",
        "InferenceSchedulerSummary$DataDelayOffsetInMinutes": "<p>A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if an offset delay time of five minutes was selected, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data. </p>",
        "UpdateInferenceSchedulerRequest$DataDelayOffsetInMinutes": "<p> A period of time (in minutes) by which inference on the data is delayed after the data starts. For instance, if you select an offset delay time of five minutes, inference will not begin on the data until the first data measurement after the five minute mark. For example, if five minutes is selected, the inference scheduler will wake up at the configured frequency with the additional five minute delay time to check the customer S3 bucket. The customer can upload data at the same frequency and they don't need to stop and restart the scheduler when uploading new data.</p>"
      }
    },
    "DataIngestionJobSummaries": {
      "base": null,
      "refs": {
        "ListDataIngestionJobsResponse$DataIngestionJobSummaries": "<p>Specifies information about the specific data ingestion job, including dataset name and status. </p>"
      }
    },
    "DataIngestionJobSummary": {
      "base": "<p>Provides information about a specified data ingestion job, including dataset information, data ingestion configuration, and status. </p>",
      "refs": {
        "DataIngestionJobSummaries$member": null
      }
    },
    "DataPreProcessingConfiguration": {
      "base": "<p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p> <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix \"PT\" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>",
      "refs": {
        "CreateModelRequest$DataPreProcessingConfiguration": "<p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p> <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix \"PT\" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>",
        "DescribeModelResponse$DataPreProcessingConfiguration": "<p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p> <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix \"PT\" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>"
      }
    },
    "DataQualitySummary": {
      "base": "<p> DataQualitySummary gives aggregated statistics over all the sensors about a completed ingestion job. It primarily gives more information about statistics over different incorrect data like MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, DuplicateTimeStamps. </p>",
      "refs": {
        "DescribeDataIngestionJobResponse$DataQualitySummary": "<p> Gives statistics about a completed ingestion job. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>",
        "DescribeDatasetResponse$DataQualitySummary": "<p> Gives statistics associated with the given dataset for the latest successful associated ingestion job id. These statistics primarily relate to quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>"
      }
    },
    "DataSizeInBytes": {
      "base": null,
      "refs": {
        "DescribeDataIngestionJobResponse$IngestedDataSize": "<p> Indicates the size of the ingested dataset. </p>"
      }
    },
    "DataUploadFrequency": {
      "base": null,
      "refs": {
        "CreateInferenceSchedulerRequest$DataUploadFrequency": "<p> How often data is uploaded to the source Amazon S3 bucket for the input data. The value chosen is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment runs inference on your data.</p> <p>For more information, see <a href=\"https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/understanding-inference-process.html\">Understanding the inference process</a>.</p>",
        "DescribeInferenceSchedulerResponse$DataUploadFrequency": "<p>Specifies how often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>",
        "InferenceSchedulerSummary$DataUploadFrequency": "<p>How often data is uploaded to the source S3 bucket for the input data. This value is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>",
        "UpdateInferenceSchedulerRequest$DataUploadFrequency": "<p>How often data is uploaded to the source S3 bucket for the input data. The value chosen is the length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for Equipment will upload the real-time data to the source bucket once every 5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on your data. In this example, it starts once every 5 minutes. </p>"
      }
    },
    "DatasetArn": {
      "base": null,
      "refs": {
        "CreateDatasetResponse$DatasetArn": "<p> The Amazon Resource Name (ARN) of the dataset being created. </p>",
        "DataIngestionJobSummary$DatasetArn": "<p>The Amazon Resource Name (ARN) of the dataset used in the data ingestion job. </p>",
        "DatasetSummary$DatasetArn": "<p>The Amazon Resource Name (ARN) of the specified dataset. </p>",
        "DescribeDataIngestionJobResponse$DatasetArn": "<p>The Amazon Resource Name (ARN) of the dataset being used in the data ingestion job. </p>",
        "DescribeDatasetResponse$DatasetArn": "<p>The Amazon Resource Name (ARN) of the dataset being described. </p>",
        "DescribeModelResponse$DatasetArn": "<p>The Amazon Resouce Name (ARN) of the dataset used to create the ML model being described. </p>",
        "ModelSummary$DatasetArn": "<p> The Amazon Resource Name (ARN) of the dataset used to create the model. </p>"
      }
    },
    "DatasetIdentifier": {
      "base": null,
      "refs": {
        "CreateModelRequest$DatasetName": "<p>The name of the dataset for the ML model being created. </p>",
        "DeleteDatasetRequest$DatasetName": "<p>The name of the dataset to be deleted. </p>",
        "DescribeDatasetRequest$DatasetName": "<p>The name of the dataset to be described. </p>",
        "StartDataIngestionJobRequest$DatasetName": "<p>The name of the dataset being used by the data ingestion job. </p>"
      }
    },
    "DatasetName": {
      "base": null,
      "refs": {
        "CreateDatasetRequest$DatasetName": "<p>The name of the dataset being created. </p>",
        "CreateDatasetResponse$DatasetName": "<p>The name of the dataset being created. </p>",
        "DataIngestionJobSummary$DatasetName": "<p>The name of the dataset used for the data ingestion job. </p>",
        "DatasetSummary$DatasetName": "<p>The name of the dataset. </p>",
        "DescribeDatasetResponse$DatasetName": "<p>The name of the dataset being described. </p>",
        "DescribeModelResponse$DatasetName": "<p>The name of the dataset being used by the ML being described. </p>",
        "ListDataIngestionJobsRequest$DatasetName": "<p>The name of the dataset being used for the data ingestion job. </p>",
        "ListDatasetsRequest$DatasetNameBeginsWith": "<p>The beginning of the name of the datasets to be listed. </p>",
        "ListModelsRequest$DatasetNameBeginsWith": "<p>The beginning of the name of the dataset of the ML models to be listed. </p>",
        "ListSensorStatisticsRequest$DatasetName": "<p> The name of the dataset associated with the list of Sensor Statistics. </p>",
        "ModelSummary$DatasetName": "<p>The name of the dataset being used for the ML model. </p>"
      }
    },
    "DatasetSchema": {
      "base": "<p>Provides information about the data schema used with the given dataset. </p>",
      "refs": {
        "CreateDatasetRequest$DatasetSchema": "<p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>",
        "CreateModelRequest$DatasetSchema": "<p>The data schema for the ML model being created. </p>"
      }
    },
    "DatasetStatus": {
      "base": null,
      "refs": {
        "CreateDatasetResponse$Status": "<p>Indicates the status of the <code>CreateDataset</code> operation. </p>",
        "DatasetSummary$Status": "<p>Indicates the status of the dataset. </p>",
        "DescribeDatasetResponse$Status": "<p>Indicates the status of the dataset. </p>"
      }
    },
    "DatasetSummaries": {
      "base": null,
      "refs": {
        "ListDatasetsResponse$DatasetSummaries": "<p>Provides information about the specified dataset, including creation time, dataset ARN, and status. </p>"
      }
    },
    "DatasetSummary": {
      "base": "<p>Contains information about the specific data set, including name, ARN, and status. </p>",
      "refs": {
        "DatasetSummaries$member": null
      }
    },
    "DeleteDatasetRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteInferenceSchedulerRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteLabelGroupRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteLabelRequest": {
      "base": null,
      "refs": {
      }
    },
    "DeleteModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "DescribeDataIngestionJobRequest": {
      "base": null,
      "refs": {
      }
    },
    "DescribeDataIngestionJobResponse": {
      "base": null,
      "refs": {
      }
    },
    "DescribeDatasetRequest": {
      "base": null,
      "refs": {
      }
    },
    "DescribeDatasetResponse": {
      "base": null,
      "refs": {
      }
    },
    "DescribeInferenceSchedulerRequest": {
      "base": null,
      "refs": {
      }
    },
    "DescribeInferenceSchedulerResponse": {
      "base": null,
      "refs": {
      }
    },
    "DescribeLabelGroupRequest": {
      "base": null,
      "refs": {
      }
    },
    "DescribeLabelGroupResponse": {
      "base": null,
      "refs": {
      }
    },
    "DescribeLabelRequest": {
      "base": null,
      "refs": {
      }
    },
    "DescribeLabelResponse": {
      "base": null,
      "refs": {
      }
    },
    "DescribeModelRequest": {
      "base": null,
      "refs": {
      }
    },
    "DescribeModelResponse": {
      "base": null,
      "refs": {
      }
    },
    "DuplicateTimestamps": {
      "base": "<p> Entity that comprises information abount duplicate timestamps in the dataset. </p>",
      "refs": {
        "DataQualitySummary$DuplicateTimestamps": "<p> Parameter that gives information about duplicate timestamps in the input data. </p>"
      }
    },
    "Equipment": {
      "base": null,
      "refs": {
        "CreateLabelRequest$Equipment": "<p> Indicates that a label pertains to a particular piece of equipment. </p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>",
        "DescribeLabelResponse$Equipment": "<p> Indicates that a label pertains to a particular piece of equipment. </p>",
        "LabelSummary$Equipment": "<p> Indicates that a label pertains to a particular piece of equipment. </p>",
        "ListLabelsRequest$Equipment": "<p> Lists the labels that pertain to a particular piece of equipment. </p>"
      }
    },
    "EventDurationInSeconds": {
      "base": null,
      "refs": {
        "InferenceEventSummary$EventDurationInSeconds": "<p> Indicates the size of an inference event in seconds. </p>"
      }
    },
    "FaultCode": {
      "base": null,
      "refs": {
        "CreateLabelRequest$FaultCode": "<p> Provides additional information about the label. The fault code must be defined in the FaultCodes attribute of the label group.</p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data. </p>",
        "DescribeLabelResponse$FaultCode": "<p> Indicates the type of anomaly associated with the label. </p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>",
        "FaultCodes$member": null,
        "LabelSummary$FaultCode": "<p> Indicates the type of anomaly associated with the label. </p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>",
        "ListLabelsRequest$FaultCode": "<p> Returns labels with a particular fault code. </p>"
      }
    },
    "FaultCodes": {
      "base": null,
      "refs": {
        "CreateLabelGroupRequest$FaultCodes": "<p> The acceptable fault codes (indicating the type of anomaly associated with the label) that can be used with this label group.</p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>",
        "DescribeLabelGroupResponse$FaultCodes": "<p> Codes indicating the type of anomaly associated with the labels in the lagbel group. </p>",
        "UpdateLabelGroupRequest$FaultCodes": "<p> Updates the code indicating the type of anomaly associated with the label. </p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>"
      }
    },
    "FileNameTimestampFormat": {
      "base": null,
      "refs": {
        "InferenceInputNameConfiguration$TimestampFormat": "<p>The format of the timestamp, whether Epoch time, or standard, with or without hyphens (-). </p>"
      }
    },
    "Float": {
      "base": null,
      "refs": {
        "CountPercent$Percentage": "<p> Indicates the percentage of occurances of the given statistic. </p>"
      }
    },
    "IamRoleArn": {
      "base": null,
      "refs": {
        "CreateInferenceSchedulerRequest$RoleArn": "<p>The Amazon Resource Name (ARN) of a role with permission to access the data source being used for the inference. </p>",
        "CreateModelRequest$RoleArn": "<p> The Amazon Resource Name (ARN) of a role with permission to access the data source being used to create the ML model. </p>",
        "DescribeDataIngestionJobResponse$RoleArn": "<p>The Amazon Resource Name (ARN) of an IAM role with permission to access the data source being ingested. </p>",
        "DescribeDatasetResponse$RoleArn": "<p> The Amazon Resource Name (ARN) of the IAM role that you are using for this the data ingestion job. </p>",
        "DescribeInferenceSchedulerResponse$RoleArn": "<p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the inference scheduler being described. </p>",
        "DescribeModelResponse$RoleArn": "<p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the ML model being described. </p>",
        "StartDataIngestionJobRequest$RoleArn": "<p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the data ingestion job. </p>",
        "UpdateInferenceSchedulerRequest$RoleArn": "<p> The Amazon Resource Name (ARN) of a role with permission to access the data source for the inference scheduler. </p>"
      }
    },
    "IdempotenceToken": {
      "base": null,
      "refs": {
        "CreateDatasetRequest$ClientToken": "<p> A unique identifier for the request. If you do not set the client request token, Amazon Lookout for Equipment generates one. </p>",
        "CreateInferenceSchedulerRequest$ClientToken": "<p> A unique identifier for the request. If you do not set the client request token, Amazon Lookout for Equipment generates one. </p>",
        "CreateLabelGroupRequest$ClientToken": "<p> A unique identifier for the request to create a label group. If you do not set the client request token, Lookout for Equipment generates one. </p>",
        "CreateLabelRequest$ClientToken": "<p> A unique identifier for the request to create a label. If you do not set the client request token, Lookout for Equipment generates one. </p>",
        "CreateModelRequest$ClientToken": "<p>A unique identifier for the request. If you do not set the client request token, Amazon Lookout for Equipment generates one. </p>",
        "StartDataIngestionJobRequest$ClientToken": "<p> A unique identifier for the request. If you do not set the client request token, Amazon Lookout for Equipment generates one. </p>"
      }
    },
    "InferenceEventSummaries": {
      "base": null,
      "refs": {
        "ListInferenceEventsResponse$InferenceEventSummaries": "<p>Provides an array of information about the individual inference events returned from the <code>ListInferenceEvents</code> operation, including scheduler used, event start time, event end time, diagnostics, and so on. </p>"
      }
    },
    "InferenceEventSummary": {
      "base": "<p>Contains information about the specific inference event, including start and end time, diagnostics information, event duration and so on.</p>",
      "refs": {
        "InferenceEventSummaries$member": null
      }
    },
    "InferenceExecutionStatus": {
      "base": null,
      "refs": {
        "InferenceExecutionSummary$Status": "<p>Indicates the status of the inference execution. </p>",
        "ListInferenceExecutionsRequest$Status": "<p>The status of the inference execution. </p>"
      }
    },
    "InferenceExecutionSummaries": {
      "base": null,
      "refs": {
        "ListInferenceExecutionsResponse$InferenceExecutionSummaries": "<p>Provides an array of information about the individual inference executions returned from the <code>ListInferenceExecutions</code> operation, including model used, inference scheduler, data configuration, and so on. </p>"
      }
    },
    "InferenceExecutionSummary": {
      "base": "<p>Contains information about the specific inference execution, including input and output data configuration, inference scheduling information, status, and so on. </p>",
      "refs": {
        "InferenceExecutionSummaries$member": null
      }
    },
    "InferenceInputConfiguration": {
      "base": "<p>Specifies configuration information for the input data for the inference, including Amazon S3 location of input data.. </p>",
      "refs": {
        "CreateInferenceSchedulerRequest$DataInputConfiguration": "<p>Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>",
        "DescribeInferenceSchedulerResponse$DataInputConfiguration": "<p> Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>",
        "InferenceExecutionSummary$DataInputConfiguration": "<p> Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>",
        "UpdateInferenceSchedulerRequest$DataInputConfiguration": "<p> Specifies information for the input data for the inference scheduler, including delimiter, format, and dataset location. </p>"
      }
    },
    "InferenceInputNameConfiguration": {
      "base": "<p>Specifies configuration information for the input data for the inference, including timestamp format and delimiter. </p>",
      "refs": {
        "InferenceInputConfiguration$InferenceInputNameConfiguration": "<p>Specifies configuration information for the input data for the inference, including timestamp format and delimiter. </p>"
      }
    },
    "InferenceOutputConfiguration": {
      "base": "<p> Specifies configuration information for the output results from for the inference, including KMS key ID and output S3 location. </p>",
      "refs": {
        "CreateInferenceSchedulerRequest$DataOutputConfiguration": "<p>Specifies configuration information for the output results for the inference scheduler, including the S3 location for the output. </p>",
        "DescribeInferenceSchedulerResponse$DataOutputConfiguration": "<p> Specifies information for the output results for the inference scheduler, including the output S3 location. </p>",
        "InferenceExecutionSummary$DataOutputConfiguration": "<p> Specifies configuration information for the output results from for the inference execution, including the output Amazon S3 location. </p>",
        "UpdateInferenceSchedulerRequest$DataOutputConfiguration": "<p> Specifies information for the output results from the inference scheduler, including the output S3 location. </p>"
      }
    },
    "InferenceS3InputConfiguration": {
      "base": "<p> Specifies configuration information for the input data for the inference, including input data S3 location. </p>",
      "refs": {
        "InferenceInputConfiguration$S3InputConfiguration": "<p> Specifies configuration information for the input data for the inference, including Amazon S3 location of input data.</p>"
      }
    },
    "InferenceS3OutputConfiguration": {
      "base": "<p> Specifies configuration information for the output results from the inference, including output S3 location. </p>",
      "refs": {
        "InferenceOutputConfiguration$S3OutputConfiguration": "<p> Specifies configuration information for the output results from for the inference, output S3 location. </p>"
      }
    },
    "InferenceSchedulerArn": {
      "base": null,
      "refs": {
        "CreateInferenceSchedulerResponse$InferenceSchedulerArn": "<p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>",
        "DescribeInferenceSchedulerResponse$InferenceSchedulerArn": "<p>The Amazon Resource Name (ARN) of the inference scheduler being described. </p>",
        "InferenceEventSummary$InferenceSchedulerArn": "<p> The Amazon Resource Name (ARN) of the inference scheduler being used for the inference event. </p>",
        "InferenceExecutionSummary$InferenceSchedulerArn": "<p> The Amazon Resource Name (ARN) of the inference scheduler being used for the inference execution. </p>",
        "InferenceSchedulerSummary$InferenceSchedulerArn": "<p> The Amazon Resource Name (ARN) of the inference scheduler. </p>",
        "StartInferenceSchedulerResponse$InferenceSchedulerArn": "<p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>",
        "StopInferenceSchedulerResponse$InferenceSchedulerArn": "<p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>"
      }
    },
    "InferenceSchedulerIdentifier": {
      "base": null,
      "refs": {
        "DeleteInferenceSchedulerRequest$InferenceSchedulerName": "<p>The name of the inference scheduler to be deleted. </p>",
        "DescribeInferenceSchedulerRequest$InferenceSchedulerName": "<p>The name of the inference scheduler being described. </p>",
        "ListInferenceEventsRequest$InferenceSchedulerName": "<p>The name of the inference scheduler for the inference events listed. </p>",
        "ListInferenceExecutionsRequest$InferenceSchedulerName": "<p>The name of the inference scheduler for the inference execution listed. </p>",
        "ListInferenceSchedulersRequest$InferenceSchedulerNameBeginsWith": "<p>The beginning of the name of the inference schedulers to be listed. </p>",
        "StartInferenceSchedulerRequest$InferenceSchedulerName": "<p>The name of the inference scheduler to be started. </p>",
        "StopInferenceSchedulerRequest$InferenceSchedulerName": "<p>The name of the inference scheduler to be stopped. </p>",
        "UpdateInferenceSchedulerRequest$InferenceSchedulerName": "<p>The name of the inference scheduler to be updated. </p>"
      }
    },
    "InferenceSchedulerName": {
      "base": null,
      "refs": {
        "CreateInferenceSchedulerRequest$InferenceSchedulerName": "<p>The name of the inference scheduler being created. </p>",
        "CreateInferenceSchedulerResponse$InferenceSchedulerName": "<p>The name of inference scheduler being created. </p>",
        "DescribeInferenceSchedulerResponse$InferenceSchedulerName": "<p>The name of the inference scheduler being described. </p>",
        "InferenceEventSummary$InferenceSchedulerName": "<p>The name of the inference scheduler being used for the inference events. </p>",
        "InferenceExecutionSummary$InferenceSchedulerName": "<p>The name of the inference scheduler being used for the inference execution. </p>",
        "InferenceSchedulerSummary$InferenceSchedulerName": "<p>The name of the inference scheduler. </p>",
        "StartInferenceSchedulerResponse$InferenceSchedulerName": "<p>The name of the inference scheduler being started. </p>",
        "StopInferenceSchedulerResponse$InferenceSchedulerName": "<p>The name of the inference scheduler being stopped. </p>"
      }
    },
    "InferenceSchedulerStatus": {
      "base": null,
      "refs": {
        "CreateInferenceSchedulerResponse$Status": "<p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>",
        "DescribeInferenceSchedulerResponse$Status": "<p>Indicates the status of the inference scheduler. </p>",
        "InferenceSchedulerSummary$Status": "<p>Indicates the status of the inference scheduler. </p>",
        "StartInferenceSchedulerResponse$Status": "<p>Indicates the status of the inference scheduler. </p>",
        "StopInferenceSchedulerResponse$Status": "<p>Indicates the status of the inference scheduler. </p>"
      }
    },
    "InferenceSchedulerSummaries": {
      "base": null,
      "refs": {
        "ListInferenceSchedulersResponse$InferenceSchedulerSummaries": "<p>Provides information about the specified inference scheduler, including data upload frequency, model name and ARN, and status. </p>"
      }
    },
    "InferenceSchedulerSummary": {
      "base": "<p>Contains information about the specific inference scheduler, including data delay offset, model name and ARN, status, and so on. </p>",
      "refs": {
        "InferenceSchedulerSummaries$member": null
      }
    },
    "IngestedFilesSummary": {
      "base": "<p>Gives statistics about how many files have been ingested, and which files have not been ingested, for a particular ingestion job.</p>",
      "refs": {
        "DescribeDataIngestionJobResponse$IngestedFilesSummary": null,
        "DescribeDatasetResponse$IngestedFilesSummary": "<p> IngestedFilesSummary associated with the given dataset for the latest successful associated ingestion job id. </p>"
      }
    },
    "IngestionInputConfiguration": {
      "base": "<p> Specifies configuration information for the input data for the data ingestion job, including input data S3 location. </p>",
      "refs": {
        "DataIngestionJobSummary$IngestionInputConfiguration": "<p> Specifies information for the input data for the data inference job, including data Amazon S3 location parameters. </p>",
        "DescribeDataIngestionJobResponse$IngestionInputConfiguration": "<p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>",
        "DescribeDatasetResponse$IngestionInputConfiguration": "<p>Specifies the S3 location configuration for the data input for the data ingestion job. </p>",
        "StartDataIngestionJobRequest$IngestionInputConfiguration": "<p> Specifies information for the input data for the data ingestion job, including dataset S3 location. </p>"
      }
    },
    "IngestionJobId": {
      "base": null,
      "refs": {
        "DataIngestionJobSummary$JobId": "<p>Indicates the job ID of the data ingestion job. </p>",
        "DescribeDataIngestionJobRequest$JobId": "<p>The job ID of the data ingestion job. </p>",
        "DescribeDataIngestionJobResponse$JobId": "<p>Indicates the job ID of the data ingestion job. </p>",
        "ListSensorStatisticsRequest$IngestionJobId": "<p> The ingestion job id associated with the list of Sensor Statistics. To get sensor statistics for a particular ingestion job id, both dataset name and ingestion job id must be submitted as inputs. </p>",
        "StartDataIngestionJobResponse$JobId": "<p>Indicates the job ID of the data ingestion job. </p>"
      }
    },
    "IngestionJobStatus": {
      "base": null,
      "refs": {
        "DataIngestionJobSummary$Status": "<p>Indicates the status of the data ingestion job. </p>",
        "DescribeDataIngestionJobResponse$Status": "<p>Indicates the status of the <code>DataIngestionJob</code> operation. </p>",
        "ListDataIngestionJobsRequest$Status": "<p>Indicates the status of the data ingestion job. </p>",
        "StartDataIngestionJobResponse$Status": "<p>Indicates the status of the <code>StartDataIngestionJob</code> operation. </p>"
      }
    },
    "IngestionS3InputConfiguration": {
      "base": "<p> Specifies S3 configuration information for the input data for the data ingestion job. </p>",
      "refs": {
        "IngestionInputConfiguration$S3InputConfiguration": "<p>The location information for the S3 bucket used for input data for the data ingestion. </p>"
      }
    },
    "InlineDataSchema": {
      "base": null,
      "refs": {
        "DatasetSchema$InlineDataSchema": "<p> </p>",
        "DescribeDatasetResponse$Schema": "<p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>",
        "DescribeModelResponse$Schema": "<p>A JSON description of the data that is in each time series dataset, including names, column names, and data types. </p>"
      }
    },
    "InsufficientSensorData": {
      "base": "<p> Entity that comprises aggregated information on sensors having insufficient data. </p>",
      "refs": {
        "DataQualitySummary$InsufficientSensorData": "<p> Parameter that gives information about insufficient data for sensors in the dataset. This includes information about those sensors that have complete data missing and those with a short date range. </p>"
      }
    },
    "Integer": {
      "base": null,
      "refs": {
        "CategoricalValues$NumberOfCategory": "<p> Indicates the number of categories in the data. </p>",
        "CountPercent$Count": "<p> Indicates the count of occurences of the given statistic. </p>",
        "DuplicateTimestamps$TotalNumberOfDuplicateTimestamps": "<p> Indicates the total number of duplicate timestamps. </p>",
        "IngestedFilesSummary$TotalNumberOfFiles": "<p>Indicates the total number of files that were submitted for ingestion.</p>",
        "IngestedFilesSummary$IngestedNumberOfFiles": "<p>Indicates the number of files that were successfully ingested.</p>",
        "InvalidSensorData$AffectedSensorCount": "<p> Indicates the number of sensors that have at least some invalid values. </p>",
        "InvalidSensorData$TotalNumberOfInvalidValues": "<p> Indicates the total number of invalid values across all the sensors. </p>",
        "LargeTimestampGaps$NumberOfLargeTimestampGaps": "<p> Indicates the number of large timestamp gaps, if there are any. </p>",
        "LargeTimestampGaps$MaxTimestampGapInDays": "<p> Indicates the size of the largest timestamp gap, in days. </p>",
        "MissingCompleteSensorData$AffectedSensorCount": "<p> Indicates the number of sensors that have data missing completely. </p>",
        "MissingSensorData$AffectedSensorCount": "<p> Indicates the number of sensors that have atleast some data missing. </p>",
        "MissingSensorData$TotalNumberOfMissingValues": "<p> Indicates the total number of missing values across all the sensors. </p>",
        "SensorsWithShortDateRange$AffectedSensorCount": "<p> Indicates the number of sensors that have less than 90 days of data. </p>",
        "UnsupportedTimestamps$TotalNumberOfUnsupportedTimestamps": "<p> Indicates the total number of unsupported timestamps across the ingested data. </p>"
      }
    },
    "InternalServerException": {
      "base": "<p> Processing of the request has failed because of an unknown error, exception or failure. </p>",
      "refs": {
      }
    },
    "InvalidSensorData": {
      "base": "<p> Entity that comprises aggregated information on sensors having insufficient data. </p>",
      "refs": {
        "DataQualitySummary$InvalidSensorData": "<p> Parameter that gives information about data that is invalid over all the sensors in the input data. </p>"
      }
    },
    "KeyPattern": {
      "base": null,
      "refs": {
        "IngestionS3InputConfiguration$KeyPattern": "<p> Pattern for matching the Amazon S3 files which will be used for ingestion. If no KeyPattern is provided, we will use the default hierarchy file structure, which is same as KeyPattern {prefix}/{component_name}/* </p>"
      }
    },
    "KmsKeyArn": {
      "base": null,
      "refs": {
        "DescribeDatasetResponse$ServerSideKmsKeyId": "<p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>",
        "DescribeInferenceSchedulerResponse$ServerSideKmsKeyId": "<p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>",
        "DescribeModelResponse$ServerSideKmsKeyId": "<p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>"
      }
    },
    "LabelGroupArn": {
      "base": null,
      "refs": {
        "CreateLabelGroupResponse$LabelGroupArn": "<p> The ARN of the label group that you have created. </p>",
        "DescribeLabelGroupResponse$LabelGroupArn": "<p> The ARN of the label group. </p>",
        "DescribeLabelResponse$LabelGroupArn": "<p> The ARN of the requested label group. </p>",
        "LabelGroupSummary$LabelGroupArn": "<p> The ARN of the label group. </p>",
        "LabelSummary$LabelGroupArn": "<p> The ARN of the label group. </p>"
      }
    },
    "LabelGroupName": {
      "base": null,
      "refs": {
        "CreateLabelGroupRequest$LabelGroupName": "<p> Names a group of labels.</p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data. </p>",
        "CreateLabelGroupResponse$LabelGroupName": "<p> The name of the label group that you have created. Data in this field will be retained for service usage. Follow best practices for the security of your data. </p>",
        "CreateLabelRequest$LabelGroupName": "<p> The name of a group of labels. </p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data. </p>",
        "DeleteLabelGroupRequest$LabelGroupName": "<p> The name of the label group that you want to delete. Data in this field will be retained for service usage. Follow best practices for the security of your data. </p>",
        "DeleteLabelRequest$LabelGroupName": "<p> The name of the label group that contains the label that you want to delete. Data in this field will be retained for service usage. Follow best practices for the security of your data. </p>",
        "DescribeLabelGroupRequest$LabelGroupName": "<p> Returns the name of the label group. </p>",
        "DescribeLabelGroupResponse$LabelGroupName": "<p> The name of the label group. </p>",
        "DescribeLabelRequest$LabelGroupName": "<p> Returns the name of the group containing the label. </p>",
        "DescribeLabelResponse$LabelGroupName": "<p> The name of the requested label group. </p>",
        "LabelGroupSummary$LabelGroupName": "<p> The name of the label group. </p>",
        "LabelSummary$LabelGroupName": "<p> The name of the label group. </p>",
        "LabelsInputConfiguration$LabelGroupName": "<p> The name of the label group to be used for label data. </p>",
        "ListLabelGroupsRequest$LabelGroupNameBeginsWith": "<p> The beginning of the name of the label groups to be listed. </p>",
        "ListLabelsRequest$LabelGroupName": "<p> Retruns the name of the label group. </p>",
        "UpdateLabelGroupRequest$LabelGroupName": "<p> The name of the label group to be updated. </p>"
      }
    },
    "LabelGroupSummaries": {
      "base": null,
      "refs": {
        "ListLabelGroupsResponse$LabelGroupSummaries": "<p> A summary of the label groups. </p>"
      }
    },
    "LabelGroupSummary": {
      "base": "<p> Contains information about the label group. </p>",
      "refs": {
        "LabelGroupSummaries$member": null
      }
    },
    "LabelId": {
      "base": null,
      "refs": {
        "CreateLabelResponse$LabelId": "<p> The ID of the label that you have created. </p>",
        "DeleteLabelRequest$LabelId": "<p> The ID of the label that you want to delete. </p>",
        "DescribeLabelRequest$LabelId": "<p> Returns the ID of the label. </p>",
        "DescribeLabelResponse$LabelId": "<p> The ID of the requested label. </p>",
        "LabelSummary$LabelId": "<p> The ID of the label. </p>"
      }
    },
    "LabelRating": {
      "base": null,
      "refs": {
        "CreateLabelRequest$Rating": "<p> Indicates whether a labeled event represents an anomaly. </p>",
        "DescribeLabelResponse$Rating": "<p> Indicates whether a labeled event represents an anomaly. </p>",
        "LabelSummary$Rating": "<p> Indicates whether a labeled event represents an anomaly. </p>"
      }
    },
    "LabelSummaries": {
      "base": null,
      "refs": {
        "ListLabelsResponse$LabelSummaries": "<p> A summary of the items in the label group. </p>"
      }
    },
    "LabelSummary": {
      "base": "<p> Information about the label. </p>",
      "refs": {
        "LabelSummaries$member": null
      }
    },
    "LabelsInputConfiguration": {
      "base": "<p>Contains the configuration information for the S3 location being used to hold label data. </p>",
      "refs": {
        "CreateModelRequest$LabelsInputConfiguration": "<p>The input configuration for the labels being used for the ML model that's being created. </p>",
        "DescribeModelResponse$LabelsInputConfiguration": "<p>Specifies configuration information about the labels input, including its S3 location. </p>"
      }
    },
    "LabelsS3InputConfiguration": {
      "base": "<p>The location information (prefix and bucket name) for the s3 location being used for label data. </p>",
      "refs": {
        "LabelsInputConfiguration$S3InputConfiguration": "<p>Contains location information for the S3 location being used for label data. </p>"
      }
    },
    "LargeTimestampGaps": {
      "base": "<p> Entity that comprises information on large gaps between consecutive timestamps in data. </p>",
      "refs": {
        "SensorStatisticsSummary$LargeTimestampGaps": "<p> Parameter that describes potential risk about whether data associated with the sensor contains one or more large gaps between consecutive timestamps. </p>"
      }
    },
    "LatestInferenceResult": {
      "base": null,
      "refs": {
        "DescribeInferenceSchedulerResponse$LatestInferenceResult": "<p>Indicates whether the latest execution for the inference scheduler was Anomalous (anomalous events found) or Normal (no anomalous events found).</p>",
        "InferenceSchedulerSummary$LatestInferenceResult": "<p>Indicates whether the latest execution for the inference scheduler was Anomalous (anomalous events found) or Normal (no anomalous events found).</p>"
      }
    },
    "ListDataIngestionJobsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListDataIngestionJobsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListDatasetsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListDatasetsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListInferenceEventsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListInferenceEventsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListInferenceExecutionsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListInferenceExecutionsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListInferenceSchedulersRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListInferenceSchedulersResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListLabelGroupsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListLabelGroupsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListLabelsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListLabelsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListModelsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListModelsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListOfDiscardedFiles": {
      "base": null,
      "refs": {
        "IngestedFilesSummary$DiscardedFiles": "<p>Indicates the number of files that were discarded. A file could be discarded because its format is invalid (for example, a jpg or pdf) or not readable.</p>"
      }
    },
    "ListSensorStatisticsRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListSensorStatisticsResponse": {
      "base": null,
      "refs": {
      }
    },
    "ListTagsForResourceRequest": {
      "base": null,
      "refs": {
      }
    },
    "ListTagsForResourceResponse": {
      "base": null,
      "refs": {
      }
    },
    "MaxResults": {
      "base": null,
      "refs": {
        "ListDataIngestionJobsRequest$MaxResults": "<p> Specifies the maximum number of data ingestion jobs to list. </p>",
        "ListDatasetsRequest$MaxResults": "<p> Specifies the maximum number of datasets to list. </p>",
        "ListInferenceEventsRequest$MaxResults": "<p>Specifies the maximum number of inference events to list. </p>",
        "ListInferenceExecutionsRequest$MaxResults": "<p>Specifies the maximum number of inference executions to list. </p>",
        "ListInferenceSchedulersRequest$MaxResults": "<p> Specifies the maximum number of inference schedulers to list. </p>",
        "ListLabelGroupsRequest$MaxResults": "<p> Specifies the maximum number of label groups to list. </p>",
        "ListLabelsRequest$MaxResults": "<p> Specifies the maximum number of labels to list. </p>",
        "ListModelsRequest$MaxResults": "<p> Specifies the maximum number of ML models to list. </p>",
        "ListSensorStatisticsRequest$MaxResults": "<p>Specifies the maximum number of sensors for which to retrieve statistics. </p>"
      }
    },
    "MissingCompleteSensorData": {
      "base": "<p> Entity that comprises information on sensors that have sensor data completely missing. </p>",
      "refs": {
        "InsufficientSensorData$MissingCompleteSensorData": "<p> Parameter that describes the total number of sensors that have data completely missing for it. </p>"
      }
    },
    "MissingSensorData": {
      "base": "<p> Entity that comprises aggregated information on sensors having missing data. </p>",
      "refs": {
        "DataQualitySummary$MissingSensorData": "<p> Parameter that gives information about data that is missing over all the sensors in the input data. </p>"
      }
    },
    "ModelArn": {
      "base": null,
      "refs": {
        "CreateModelResponse$ModelArn": "<p>The Amazon Resource Name (ARN) of the model being created. </p>",
        "DescribeInferenceSchedulerResponse$ModelArn": "<p>The Amazon Resource Name (ARN) of the ML model of the inference scheduler being described. </p>",
        "DescribeModelResponse$ModelArn": "<p>The Amazon Resource Name (ARN) of the ML model being described. </p>",
        "InferenceExecutionSummary$ModelArn": "<p>The Amazon Resource Name (ARN) of the ML model used for the inference execution. </p>",
        "InferenceSchedulerSummary$ModelArn": "<p> The Amazon Resource Name (ARN) of the ML model used by the inference scheduler. </p>",
        "ModelSummary$ModelArn": "<p> The Amazon Resource Name (ARN) of the ML model. </p>",
        "StartInferenceSchedulerResponse$ModelArn": "<p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler. </p>",
        "StopInferenceSchedulerResponse$ModelArn": "<p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being stopped. </p>"
      }
    },
    "ModelMetrics": {
      "base": null,
      "refs": {
        "DescribeModelResponse$ModelMetrics": "<p>The Model Metrics show an aggregated summary of the model's performance within the evaluation time range. This is the JSON content of the metrics created when evaluating the model. </p>",
        "InferenceEventSummary$Diagnostics": "<p> An array which specifies the names and values of all sensors contributing to an inference event.</p>"
      }
    },
    "ModelName": {
      "base": null,
      "refs": {
        "CreateInferenceSchedulerRequest$ModelName": "<p>The name of the previously trained ML model being used to create the inference scheduler. </p>",
        "CreateModelRequest$ModelName": "<p>The name for the ML model to be created.</p>",
        "DeleteModelRequest$ModelName": "<p>The name of the ML model to be deleted. </p>",
        "DescribeInferenceSchedulerResponse$ModelName": "<p>The name of the ML model of the inference scheduler being described. </p>",
        "DescribeModelRequest$ModelName": "<p>The name of the ML model to be described. </p>",
        "DescribeModelResponse$ModelName": "<p>The name of the ML model being described. </p>",
        "InferenceExecutionSummary$ModelName": "<p>The name of the ML model being used for the inference execution. </p>",
        "InferenceSchedulerSummary$ModelName": "<p>The name of the ML model used for the inference scheduler. </p>",
        "ListInferenceSchedulersRequest$ModelName": "<p>The name of the ML model used by the inference scheduler to be listed. </p>",
        "ListModelsRequest$ModelNameBeginsWith": "<p>The beginning of the name of the ML models being listed. </p>",
        "ModelSummary$ModelName": "<p>The name of the ML model. </p>",
        "StartInferenceSchedulerResponse$ModelName": "<p>The name of the ML model being used by the inference scheduler. </p>",
        "StopInferenceSchedulerResponse$ModelName": "<p>The name of the ML model used by the inference scheduler being stopped. </p>"
      }
    },
    "ModelStatus": {
      "base": null,
      "refs": {
        "CreateModelResponse$Status": "<p>Indicates the status of the <code>CreateModel</code> operation. </p>",
        "DescribeModelResponse$Status": "<p>Specifies the current status of the model being described. Status describes the status of the most recent action of the model. </p>",
        "ListModelsRequest$Status": "<p>The status of the ML model. </p>",
        "ModelSummary$Status": "<p>Indicates the status of the ML model. </p>"
      }
    },
    "ModelSummaries": {
      "base": null,
      "refs": {
        "ListModelsResponse$ModelSummaries": "<p>Provides information on the specified model, including created time, model and dataset ARNs, and status. </p>"
      }
    },
    "ModelSummary": {
      "base": "<p>Provides information about the specified ML model, including dataset and model names and ARNs, as well as status. </p>",
      "refs": {
        "ModelSummaries$member": null
      }
    },
    "MonotonicValues": {
      "base": "<p> Entity that comprises information on monotonic values in the data. </p>",
      "refs": {
        "SensorStatisticsSummary$MonotonicValues": "<p> Parameter that describes potential risk about whether data associated with the sensor is mostly monotonic. </p>"
      }
    },
    "Monotonicity": {
      "base": null,
      "refs": {
        "MonotonicValues$Monotonicity": "<p> Indicates the monotonicity of values. Can be INCREASING, DECREASING, or STATIC. </p>"
      }
    },
    "MultipleOperatingModes": {
      "base": "<p> Entity that comprises information on operating modes in data. </p>",
      "refs": {
        "SensorStatisticsSummary$MultipleOperatingModes": "<p> Parameter that describes potential risk about whether data associated with the sensor has more than one operating mode. </p>"
      }
    },
    "NameOrArn": {
      "base": null,
      "refs": {
        "CreateDatasetRequest$ServerSideKmsKeyId": "<p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout for Equipment. </p>",
        "CreateInferenceSchedulerRequest$ServerSideKmsKeyId": "<p>Provides the identifier of the KMS key used to encrypt inference scheduler data by Amazon Lookout for Equipment. </p>",
        "CreateModelRequest$ServerSideKmsKeyId": "<p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout for Equipment. </p>",
        "InferenceOutputConfiguration$KmsKeyId": "<p>The ID number for the AWS KMS key used to encrypt the inference output. </p>"
      }
    },
    "NextToken": {
      "base": null,
      "refs": {
        "ListDataIngestionJobsRequest$NextToken": "<p>An opaque pagination token indicating where to continue the listing of data ingestion jobs. </p>",
        "ListDataIngestionJobsResponse$NextToken": "<p> An opaque pagination token indicating where to continue the listing of data ingestion jobs. </p>",
        "ListDatasetsRequest$NextToken": "<p> An opaque pagination token indicating where to continue the listing of datasets. </p>",
        "ListDatasetsResponse$NextToken": "<p> An opaque pagination token indicating where to continue the listing of datasets. </p>",
        "ListInferenceEventsRequest$NextToken": "<p>An opaque pagination token indicating where to continue the listing of inference events.</p>",
        "ListInferenceEventsResponse$NextToken": "<p>An opaque pagination token indicating where to continue the listing of inference executions. </p>",
        "ListInferenceExecutionsRequest$NextToken": "<p>An opaque pagination token indicating where to continue the listing of inference executions.</p>",
        "ListInferenceExecutionsResponse$NextToken": "<p> An opaque pagination token indicating where to continue the listing of inference executions. </p>",
        "ListInferenceSchedulersRequest$NextToken": "<p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>",
        "ListInferenceSchedulersResponse$NextToken": "<p> An opaque pagination token indicating where to continue the listing of inference schedulers. </p>",
        "ListLabelGroupsRequest$NextToken": "<p> An opaque pagination token indicating where to continue the listing of label groups. </p>",
        "ListLabelGroupsResponse$NextToken": "<p> An opaque pagination token indicating where to continue the listing of label groups. </p>",
        "ListLabelsRequest$NextToken": "<p> An opaque pagination token indicating where to continue the listing of label groups. </p>",
        "ListLabelsResponse$NextToken": "<p> An opaque pagination token indicating where to continue the listing of datasets. </p>",
        "ListModelsRequest$NextToken": "<p> An opaque pagination token indicating where to continue the listing of ML models. </p>",
        "ListModelsResponse$NextToken": "<p> An opaque pagination token indicating where to continue the listing of ML models. </p>",
        "ListSensorStatisticsRequest$NextToken": "<p>An opaque pagination token indicating where to continue the listing of sensor statistics. </p>",
        "ListSensorStatisticsResponse$NextToken": "<p>An opaque pagination token indicating where to continue the listing of sensor statistics. </p>"
      }
    },
    "OffCondition": {
      "base": null,
      "refs": {
        "CreateModelRequest$OffCondition": "<p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>",
        "DescribeModelResponse$OffCondition": "<p>Indicates that the asset associated with this sensor has been shut off. As long as this condition is met, Lookout for Equipment will not use data from this asset for training, evaluation, or inference.</p>"
      }
    },
    "ResourceNotFoundException": {
      "base": "<p> The resource requested could not be found. Verify the resource ID and retry your request. </p>",
      "refs": {
      }
    },
    "S3Bucket": {
      "base": null,
      "refs": {
        "InferenceS3InputConfiguration$Bucket": "<p>The bucket containing the input dataset for the inference. </p>",
        "InferenceS3OutputConfiguration$Bucket": "<p> The bucket containing the output results from the inference </p>",
        "IngestionS3InputConfiguration$Bucket": "<p>The name of the S3 bucket used for the input data for the data ingestion. </p>",
        "LabelsS3InputConfiguration$Bucket": "<p>The name of the S3 bucket holding the label data. </p>",
        "S3Object$Bucket": "<p>The name of the specific S3 bucket. </p>"
      }
    },
    "S3Key": {
      "base": null,
      "refs": {
        "S3Object$Key": "<p>The AWS Key Management Service (AWS KMS) key being used to encrypt the S3 object. Without this key, data in the bucket is not accessible. </p>"
      }
    },
    "S3Object": {
      "base": "<p>Contains information about an S3 bucket. </p>",
      "refs": {
        "InferenceExecutionSummary$CustomerResultObject": "<p> </p>",
        "ListOfDiscardedFiles$member": null
      }
    },
    "S3Prefix": {
      "base": null,
      "refs": {
        "InferenceS3InputConfiguration$Prefix": "<p>The prefix for the S3 bucket used for the input data for the inference. </p>",
        "InferenceS3OutputConfiguration$Prefix": "<p> The prefix for the S3 bucket used for the output results from the inference. </p>",
        "IngestionS3InputConfiguration$Prefix": "<p>The prefix for the S3 location being used for the input data for the data ingestion. </p>",
        "LabelsS3InputConfiguration$Prefix": "<p> The prefix for the S3 bucket used for the label data. </p>"
      }
    },
    "SensorName": {
      "base": null,
      "refs": {
        "SensorStatisticsSummary$SensorName": "<p> Name of the sensor that the statistics belong to. </p>"
      }
    },
    "SensorStatisticsSummaries": {
      "base": null,
      "refs": {
        "ListSensorStatisticsResponse$SensorStatisticsSummaries": "<p>Provides ingestion-based statistics regarding the specified sensor with respect to various validation types, such as whether data exists, the number and percentage of missing values, and the number and percentage of duplicate timestamps. </p>"
      }
    },
    "SensorStatisticsSummary": {
      "base": "<p> Summary of ingestion statistics like whether data exists, number of missing values, number of invalid values and so on related to the particular sensor. </p>",
      "refs": {
        "SensorStatisticsSummaries$member": null
      }
    },
    "SensorsWithShortDateRange": {
      "base": "<p> Entity that comprises information on sensors that have shorter date range. </p>",
      "refs": {
        "InsufficientSensorData$SensorsWithShortDateRange": "<p> Parameter that describes the total number of sensors that have a short date range of less than 90 days of data overall. </p>"
      }
    },
    "ServiceQuotaExceededException": {
      "base": "<p> Resource limitations have been exceeded. </p>",
      "refs": {
      }
    },
    "StartDataIngestionJobRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartDataIngestionJobResponse": {
      "base": null,
      "refs": {
      }
    },
    "StartInferenceSchedulerRequest": {
      "base": null,
      "refs": {
      }
    },
    "StartInferenceSchedulerResponse": {
      "base": null,
      "refs": {
      }
    },
    "StatisticalIssueStatus": {
      "base": null,
      "refs": {
        "CategoricalValues$Status": "<p> Indicates whether there is a potential data issue related to categorical values. </p>",
        "LargeTimestampGaps$Status": "<p> Indicates whether there is a potential data issue related to large gaps in timestamps. </p>",
        "MonotonicValues$Status": "<p> Indicates whether there is a potential data issue related to having monotonic values. </p>",
        "MultipleOperatingModes$Status": "<p> Indicates whether there is a potential data issue related to having multiple operating modes. </p>"
      }
    },
    "StopInferenceSchedulerRequest": {
      "base": null,
      "refs": {
      }
    },
    "StopInferenceSchedulerResponse": {
      "base": null,
      "refs": {
      }
    },
    "Tag": {
      "base": "<p>A tag is a key-value pair that can be added to a resource as metadata. </p>",
      "refs": {
        "TagList$member": null
      }
    },
    "TagKey": {
      "base": null,
      "refs": {
        "Tag$Key": "<p>The key for the specified tag. </p>",
        "TagKeyList$member": null
      }
    },
    "TagKeyList": {
      "base": null,
      "refs": {
        "UntagResourceRequest$TagKeys": "<p>Specifies the key of the tag to be removed from a specified resource. </p>"
      }
    },
    "TagList": {
      "base": null,
      "refs": {
        "CreateDatasetRequest$Tags": "<p>Any tags associated with the ingested data described in the dataset. </p>",
        "CreateInferenceSchedulerRequest$Tags": "<p>Any tags associated with the inference scheduler. </p>",
        "CreateLabelGroupRequest$Tags": "<p> Tags that provide metadata about the label group you are creating. </p> <p>Data in this field will be retained for service usage. Follow best practices for the security of your data.</p>",
        "CreateModelRequest$Tags": "<p> Any tags associated with the ML model being created. </p>",
        "ListTagsForResourceResponse$Tags": "<p> Any tags associated with the resource. </p>",
        "TagResourceRequest$Tags": "<p>The tag or tags to be associated with a specific resource. Both the tag key and value are specified. </p>"
      }
    },
    "TagResourceRequest": {
      "base": null,
      "refs": {
      }
    },
    "TagResourceResponse": {
      "base": null,
      "refs": {
      }
    },
    "TagValue": {
      "base": null,
      "refs": {
        "Tag$Value": "<p>The value for the specified tag. </p>"
      }
    },
    "TargetSamplingRate": {
      "base": null,
      "refs": {
        "DataPreProcessingConfiguration$TargetSamplingRate": "<p>The sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p> <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix \"PT\" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>"
      }
    },
    "ThrottlingException": {
      "base": "<p>The request was denied due to request throttling.</p>",
      "refs": {
      }
    },
    "TimeZoneOffset": {
      "base": null,
      "refs": {
        "InferenceInputConfiguration$InputTimeZoneOffset": "<p>Indicates the difference between your time zone and Coordinated Universal Time (UTC).</p>"
      }
    },
    "Timestamp": {
      "base": null,
      "refs": {
        "CreateLabelRequest$StartTime": "<p> The start time of the labeled event. </p>",
        "CreateLabelRequest$EndTime": "<p> The end time of the labeled event. </p>",
        "CreateModelRequest$TrainingDataStartTime": "<p>Indicates the time reference in the dataset that should be used to begin the subset of training data for the ML model. </p>",
        "CreateModelRequest$TrainingDataEndTime": "<p>Indicates the time reference in the dataset that should be used to end the subset of training data for the ML model. </p>",
        "CreateModelRequest$EvaluationDataStartTime": "<p>Indicates the time reference in the dataset that should be used to begin the subset of evaluation data for the ML model. </p>",
        "CreateModelRequest$EvaluationDataEndTime": "<p> Indicates the time reference in the dataset that should be used to end the subset of evaluation data for the ML model. </p>",
        "DatasetSummary$CreatedAt": "<p>The time at which the dataset was created in Amazon Lookout for Equipment. </p>",
        "DescribeDataIngestionJobResponse$CreatedAt": "<p>The time at which the data ingestion job was created. </p>",
        "DescribeDataIngestionJobResponse$DataStartTime": "<p> Indicates the earliest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>",
        "DescribeDataIngestionJobResponse$DataEndTime": "<p> Indicates the latest timestamp corresponding to data that was successfully ingested during this specific ingestion job. </p>",
        "DescribeDatasetResponse$CreatedAt": "<p>Specifies the time the dataset was created in Lookout for Equipment. </p>",
        "DescribeDatasetResponse$LastUpdatedAt": "<p>Specifies the time the dataset was last updated, if it was. </p>",
        "DescribeDatasetResponse$DataStartTime": "<p> Indicates the earliest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>",
        "DescribeDatasetResponse$DataEndTime": "<p> Indicates the latest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset. </p>",
        "DescribeInferenceSchedulerResponse$CreatedAt": "<p>Specifies the time at which the inference scheduler was created. </p>",
        "DescribeInferenceSchedulerResponse$UpdatedAt": "<p>Specifies the time at which the inference scheduler was last updated, if it was. </p>",
        "DescribeLabelGroupResponse$CreatedAt": "<p> The time at which the label group was created. </p>",
        "DescribeLabelGroupResponse$UpdatedAt": "<p> The time at which the label group was updated. </p>",
        "DescribeLabelResponse$StartTime": "<p> The start time of the requested label. </p>",
        "DescribeLabelResponse$EndTime": "<p> The end time of the requested label. </p>",
        "DescribeLabelResponse$CreatedAt": "<p> The time at which the label was created. </p>",
        "DescribeModelResponse$TrainingDataStartTime": "<p> Indicates the time reference in the dataset that was used to begin the subset of training data for the ML model. </p>",
        "DescribeModelResponse$TrainingDataEndTime": "<p> Indicates the time reference in the dataset that was used to end the subset of training data for the ML model. </p>",
        "DescribeModelResponse$EvaluationDataStartTime": "<p> Indicates the time reference in the dataset that was used to begin the subset of evaluation data for the ML model. </p>",
        "DescribeModelResponse$EvaluationDataEndTime": "<p> Indicates the time reference in the dataset that was used to end the subset of evaluation data for the ML model. </p>",
        "DescribeModelResponse$TrainingExecutionStartTime": "<p>Indicates the time at which the training of the ML model began. </p>",
        "DescribeModelResponse$TrainingExecutionEndTime": "<p>Indicates the time at which the training of the ML model was completed. </p>",
        "DescribeModelResponse$LastUpdatedTime": "<p>Indicates the last time the ML model was updated. The type of update is not specified. </p>",
        "DescribeModelResponse$CreatedAt": "<p>Indicates the time and date at which the ML model was created. </p>",
        "InferenceEventSummary$EventStartTime": "<p>Indicates the starting time of an inference event. </p>",
        "InferenceEventSummary$EventEndTime": "<p>Indicates the ending time of an inference event. </p>",
        "InferenceExecutionSummary$ScheduledStartTime": "<p>Indicates the start time at which the inference scheduler began the specific inference execution. </p>",
        "InferenceExecutionSummary$DataStartTime": "<p>Indicates the time reference in the dataset at which the inference execution began. </p>",
        "InferenceExecutionSummary$DataEndTime": "<p>Indicates the time reference in the dataset at which the inference execution stopped. </p>",
        "LabelGroupSummary$CreatedAt": "<p> The time at which the label group was created. </p>",
        "LabelGroupSummary$UpdatedAt": "<p> The time at which the label group was updated. </p>",
        "LabelSummary$StartTime": "<p> The timestamp indicating the start of the label. </p>",
        "LabelSummary$EndTime": "<p> The timestamp indicating the end of the label. </p>",
        "LabelSummary$CreatedAt": "<p> The time at which the label was created. </p>",
        "ListInferenceEventsRequest$IntervalStartTime": "<p> Lookout for Equipment will return all the inference events with an end time equal to or greater than the start time given.</p>",
        "ListInferenceEventsRequest$IntervalEndTime": "<p>Returns all the inference events with an end start time equal to or greater than less than the end time given</p>",
        "ListInferenceExecutionsRequest$DataStartTimeAfter": "<p>The time reference in the inferenced dataset after which Amazon Lookout for Equipment started the inference execution. </p>",
        "ListInferenceExecutionsRequest$DataEndTimeBefore": "<p>The time reference in the inferenced dataset before which Amazon Lookout for Equipment stopped the inference execution. </p>",
        "ListLabelsRequest$IntervalStartTime": "<p> Returns all the labels with a end time equal to or later than the start time given. </p>",
        "ListLabelsRequest$IntervalEndTime": "<p> Returns all labels with a start time earlier than the end time given. </p>",
        "ModelSummary$CreatedAt": "<p>The time at which the specific model was created. </p>",
        "SensorStatisticsSummary$DataStartTime": "<p> Indicates the time reference to indicate the beginning of valid data associated with the sensor that the statistics belong to. </p>",
        "SensorStatisticsSummary$DataEndTime": "<p> Indicates the time reference to indicate the end of valid data associated with the sensor that the statistics belong to. </p>"
      }
    },
    "UnsupportedTimestamps": {
      "base": "<p> Entity that comprises information abount unsupported timestamps in the dataset. </p>",
      "refs": {
        "DataQualitySummary$UnsupportedTimestamps": "<p> Parameter that gives information about unsupported timestamps in the input data. </p>"
      }
    },
    "UntagResourceRequest": {
      "base": null,
      "refs": {
      }
    },
    "UntagResourceResponse": {
      "base": null,
      "refs": {
      }
    },
    "UpdateInferenceSchedulerRequest": {
      "base": null,
      "refs": {
      }
    },
    "UpdateLabelGroupRequest": {
      "base": null,
      "refs": {
      }
    },
    "ValidationException": {
      "base": "<p> The input fails to satisfy constraints specified by Amazon Lookout for Equipment or a related AWS service that's being utilized. </p>",
      "refs": {
      }
    }
  }
}
